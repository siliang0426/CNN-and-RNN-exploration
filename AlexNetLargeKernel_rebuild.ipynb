{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\shigo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from absl import app, flags\n",
    "from skimage import io\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "task_type = 'training'\n",
    "experiment_name = 'exp'\n",
    "label_type = 'category'\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0\n",
    "batch_size  = 256\n",
    "epochs = 5\n",
    "LABEL_SIZE = {'domain': 4, 'category': 7}\n",
    "\n",
    "class PACSDataset(Dataset):\n",
    "\n",
    "  def __init__(self,\n",
    "               root_dir,\n",
    "               label_type='domain',\n",
    "               is_training=False,\n",
    "               transform=None):\n",
    "    self.root_dir = os.path.join(root_dir, 'train' if is_training else 'val')\n",
    "    self.label_type = label_type\n",
    "    self.is_training = is_training\n",
    "    if transform:\n",
    "      self.transform = transform\n",
    "    else:\n",
    "      self.transform = transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize(mean=[0.7659, 0.7463, 0.7173],\n",
    "                               std=[0.3089, 0.3181, 0.3470]),\n",
    "      ])\n",
    "\n",
    "    self.dataset, self.label_list = self.initialize_dataset()\n",
    "    self.label_to_id = {x: i for i, x in enumerate(self.label_list)}\n",
    "    self.id_to_label = {i: x for i, x in enumerate(self.label_list)}\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image, label = self.dataset[idx]\n",
    "    label_id = self.label_to_id[label]\n",
    "    image = self.transform(image)\n",
    "    return image, label_id\n",
    "\n",
    "  def initialize_dataset(self):\n",
    "    assert os.path.isdir(self.root_dir), \\\n",
    "        '`root_dir` is not found at %s' % self.root_dir\n",
    "\n",
    "    dataset = []\n",
    "    domain_set = set()\n",
    "    category_set = set()\n",
    "    cnt = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(self.root_dir, topdown=True):\n",
    "      if files:\n",
    "        parts = root.split(os.sep)\n",
    "        if len(parts) >= 3:\n",
    "          domain = parts[-2]\n",
    "          category = parts[-1]\n",
    "          domain_set.add(domain)\n",
    "          category_set.add(category)\n",
    "          pbar = tqdm(files)\n",
    "          for name in pbar:\n",
    "            pbar.set_description('Processing Folder: domain=%s, category=%s' %\n",
    "                                (domain, category))\n",
    "            img_array = io.imread(os.path.join(root, name))\n",
    "            dataset.append((img_array, domain, category))\n",
    "    # use this below if you are running on google colab\n",
    "    # for root, dirs, files in os.walk(self.root_dir, topdown=True):\n",
    "    #   if files:\n",
    "    #     _, domain, category = root.rsplit('/', maxsplit=2)\n",
    "    #     domain_set.add(domain)\n",
    "    #     category_set.add(category)\n",
    "    #     pbar = tqdm(files)\n",
    "    #     for name in pbar:\n",
    "    #       pbar.set_description('Processing Folder: domain=%s, category=%s' %\n",
    "    #                            (domain, category))\n",
    "    #       img_array = io.imread(os.path.join(root, name))\n",
    "    #       dataset.append((img_array, domain, category))\n",
    "    images, domains, categories = zip(*dataset)\n",
    "\n",
    "    if self.label_type == 'domain':\n",
    "      labels = sorted(domain_set)\n",
    "      dataset = list(zip(images, domains))\n",
    "    elif self.label_type == 'category':\n",
    "      labels = sorted(category_set)\n",
    "      dataset = list(zip(images, categories))\n",
    "    else:\n",
    "      raise ValueError(\n",
    "          'Unknown `label_type`: Expecting `domain` or `category`.')\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "\n",
    "class AlexNetLargeKernel(nn.Module):\n",
    "\n",
    "  def __init__(self, configs):\n",
    "    super().__init__()\n",
    "    dropout = configs['dropout']\n",
    "    num_classes = configs['num_classes']\n",
    "\n",
    "    self.features = nn.Sequential(\n",
    "      nn.Conv2d(3, 96, kernel_size=21, stride=8, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(96, 256, kernel_size=7, stride=2,padding=2),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(384, 256, kernel_size=3, stride=2),\n",
    "      nn.ReLU(inplace=True),\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Dropout(dropout),\n",
    "      nn.Linear(9216, 4096),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Dropout(dropout),\n",
    "      nn.Linear(4096, 4096),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(4096, num_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "def model_training():\n",
    "\n",
    "  best_model = None\n",
    "  best_acc = 0.0\n",
    "\n",
    "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "  expt_name = 'experiments/{}/{}_lr_{}.wd_{}'.format(experiment_name, label_type, learning_rate, weight_decay)\n",
    "\n",
    "  os.makedirs(expt_name, exist_ok=True)\n",
    "  writer = SummaryWriter(log_dir=expt_name)\n",
    "\n",
    "  configs = {'num_classes': LABEL_SIZE[label_type], 'dropout': 0.5}\n",
    "\n",
    "  model = AlexNetLargeKernel(configs).to(device)\n",
    "\n",
    "  print('Model Architecture:\\n%s' % model)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "  optimizer = torch.optim.Adam(model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               weight_decay=weight_decay)\n",
    "\n",
    "  try:\n",
    "    for epoch in range(epochs):\n",
    "      print(epoch)\n",
    "      for phase in ('train', 'eval'):\n",
    "        if phase == 'train':\n",
    "          model.train()\n",
    "          dataset = train_dataset\n",
    "          data_loader = train_loader\n",
    "        else:\n",
    "          model.eval()\n",
    "          dataset = val_dataset\n",
    "          data_loader = val_loader\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for step, (images, labels) in enumerate(data_loader):\n",
    "          print(step)\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if phase == 'train':\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "\n",
    "              writer.add_scalar('Loss/{}'.format(phase), loss.item(),\n",
    "                                epoch * len(data_loader) + step)\n",
    "\n",
    "          running_loss += loss.item() * images.size(0)\n",
    "          running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataset)\n",
    "        writer.add_scalar('Epoch_Loss/{}'.format(phase), epoch_loss, epoch)\n",
    "        writer.add_scalar('Epoch_Accuracy/{}'.format(phase), epoch_acc, epoch)\n",
    "        print('[Epoch %d] %s accuracy: %.4f, loss: %.4f' %\n",
    "              (epoch + 1, phase, epoch_acc, epoch_loss))\n",
    "\n",
    "        if phase == 'eval':\n",
    "          if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model, os.path.join(expt_name, 'best_model.pt'))\n",
    "\n",
    "  except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folder: domain=art_painting, category=dog:   0%|          | 0/348 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folder: domain=art_painting, category=dog: 100%|██████████| 348/348 [00:03<00:00, 98.61it/s] \n",
      "Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 227/227 [00:02<00:00, 100.82it/s]\n",
      "Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 254/254 [00:02<00:00, 98.99it/s] \n",
      "Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 169/169 [00:01<00:00, 98.01it/s] \n",
      "Processing Folder: domain=art_painting, category=horse: 100%|██████████| 179/179 [00:01<00:00, 94.67it/s] \n",
      "Processing Folder: domain=art_painting, category=house: 100%|██████████| 262/262 [00:02<00:00, 95.19it/s] \n",
      "Processing Folder: domain=art_painting, category=person: 100%|██████████| 404/404 [00:04<00:00, 94.33it/s] \n",
      "Processing Folder: domain=cartoon, category=dog: 100%|██████████| 343/343 [00:03<00:00, 98.90it/s] \n",
      "Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 411/411 [00:04<00:00, 96.24it/s] \n",
      "Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 314/314 [00:03<00:00, 98.07it/s] \n",
      "Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 123/123 [00:01<00:00, 95.95it/s] \n",
      "Processing Folder: domain=cartoon, category=horse: 100%|██████████| 299/299 [00:03<00:00, 99.50it/s] \n",
      "Processing Folder: domain=cartoon, category=house: 100%|██████████| 266/266 [00:02<00:00, 95.32it/s] \n",
      "Processing Folder: domain=cartoon, category=person: 100%|██████████| 364/364 [00:03<00:00, 93.38it/s] \n",
      "Processing Folder: domain=photo, category=dog: 100%|██████████| 169/169 [00:01<00:00, 95.02it/s]\n",
      "Processing Folder: domain=photo, category=elephant: 100%|██████████| 181/181 [00:01<00:00, 96.66it/s]\n",
      "Processing Folder: domain=photo, category=giraffe: 100%|██████████| 165/165 [00:01<00:00, 95.42it/s]\n",
      "Processing Folder: domain=photo, category=guitar: 100%|██████████| 167/167 [00:01<00:00, 96.22it/s]\n",
      "Processing Folder: domain=photo, category=horse: 100%|██████████| 186/186 [00:01<00:00, 93.90it/s]\n",
      "Processing Folder: domain=photo, category=house: 100%|██████████| 243/243 [00:02<00:00, 95.17it/s] \n",
      "Processing Folder: domain=photo, category=person: 100%|██████████| 383/383 [00:04<00:00, 94.93it/s] \n",
      "Processing Folder: domain=sketch, category=dog: 100%|██████████| 697/697 [00:07<00:00, 94.57it/s] \n",
      "Processing Folder: domain=sketch, category=elephant: 100%|██████████| 674/674 [00:07<00:00, 92.79it/s]\n",
      "Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 681/681 [00:07<00:00, 93.16it/s] \n",
      "Processing Folder: domain=sketch, category=guitar: 100%|██████████| 564/564 [00:06<00:00, 93.22it/s] \n",
      "Processing Folder: domain=sketch, category=horse: 100%|██████████| 736/736 [00:08<00:00, 91.90it/s] \n",
      "Processing Folder: domain=sketch, category=house: 100%|██████████| 75/75 [00:00<00:00, 97.06it/s]\n",
      "Processing Folder: domain=sketch, category=person: 100%|██████████| 143/143 [00:01<00:00, 97.58it/s]\n",
      "Processing Folder: domain=art_painting, category=dog: 100%|██████████| 31/31 [00:00<00:00, 92.51it/s] \n",
      "Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 28/28 [00:00<00:00, 86.50it/s]\n",
      "Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 31/31 [00:00<00:00, 89.22it/s]\n",
      "Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 15/15 [00:00<00:00, 96.27it/s]\n",
      "Processing Folder: domain=art_painting, category=horse: 100%|██████████| 22/22 [00:00<00:00, 96.73it/s]\n",
      "Processing Folder: domain=art_painting, category=house: 100%|██████████| 33/33 [00:00<00:00, 101.29it/s]\n",
      "Processing Folder: domain=art_painting, category=person: 100%|██████████| 45/45 [00:00<00:00, 91.27it/s] \n",
      "Processing Folder: domain=cartoon, category=dog: 100%|██████████| 46/46 [00:00<00:00, 92.67it/s] \n",
      "Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 46/46 [00:00<00:00, 88.04it/s]\n",
      "Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 32/32 [00:00<00:00, 81.96it/s]\n",
      "Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 12/12 [00:00<00:00, 90.26it/s]\n",
      "Processing Folder: domain=cartoon, category=horse: 100%|██████████| 25/25 [00:00<00:00, 113.05it/s]\n",
      "Processing Folder: domain=cartoon, category=house: 100%|██████████| 22/22 [00:00<00:00, 99.02it/s] \n",
      "Processing Folder: domain=cartoon, category=person: 100%|██████████| 41/41 [00:00<00:00, 99.70it/s] \n",
      "Processing Folder: domain=photo, category=dog: 100%|██████████| 20/20 [00:00<00:00, 89.37it/s]\n",
      "Processing Folder: domain=photo, category=elephant: 100%|██████████| 21/21 [00:00<00:00, 99.37it/s] \n",
      "Processing Folder: domain=photo, category=giraffe: 100%|██████████| 17/17 [00:00<00:00, 100.97it/s]\n",
      "Processing Folder: domain=photo, category=guitar: 100%|██████████| 19/19 [00:00<00:00, 91.16it/s] \n",
      "Processing Folder: domain=photo, category=horse: 100%|██████████| 13/13 [00:00<00:00, 104.58it/s]\n",
      "Processing Folder: domain=photo, category=house: 100%|██████████| 37/37 [00:00<00:00, 90.39it/s]\n",
      "Processing Folder: domain=photo, category=person: 100%|██████████| 49/49 [00:00<00:00, 90.08it/s]\n",
      "Processing Folder: domain=sketch, category=dog: 100%|██████████| 75/75 [00:00<00:00, 83.83it/s]\n",
      "Processing Folder: domain=sketch, category=elephant: 100%|██████████| 66/66 [00:00<00:00, 94.71it/s]\n",
      "Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 72/72 [00:00<00:00, 86.25it/s] \n",
      "Processing Folder: domain=sketch, category=guitar: 100%|██████████| 44/44 [00:00<00:00, 85.26it/s]\n",
      "Processing Folder: domain=sketch, category=horse: 100%|██████████| 80/80 [00:00<00:00, 87.80it/s]\n",
      "Processing Folder: domain=sketch, category=house: 100%|██████████| 5/5 [00:00<00:00, 81.11it/s]\n",
      "Processing Folder: domain=sketch, category=person: 100%|██████████| 17/17 [00:00<00:00, 77.28it/s]\n"
     ]
    }
   ],
   "source": [
    "  train_dataset = PACSDataset(root_dir='pacs_dataset',\n",
    "                              label_type=label_type,\n",
    "                              is_training=True)\n",
    "  train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "  val_dataset = PACSDataset(root_dir='pacs_dataset',\n",
    "                            label_type=label_type,\n",
    "                            is_training=False)\n",
    "  val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "AlexNetLargeKernel(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(21, 21), stride=(8, 8), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(96, 256, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (9): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Linear(in_features=4096, out_features=7, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 1] train accuracy: 0.2270, loss: 1.8514\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 1] eval accuracy: 0.3019, loss: 1.7504\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 2] train accuracy: 0.3662, loss: 1.6261\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 2] eval accuracy: 0.4326, loss: 1.4646\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 3] train accuracy: 0.4679, loss: 1.3730\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 3] eval accuracy: 0.5156, loss: 1.3031\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 4] train accuracy: 0.5244, loss: 1.2400\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 4] eval accuracy: 0.5301, loss: 1.2292\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 5] train accuracy: 0.5625, loss: 1.1556\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 5] eval accuracy: 0.5778, loss: 1.1296\n"
     ]
    }
   ],
   "source": [
    "model_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category_Label:\n",
    "[Epoch 5] train accuracy: 0.5625, loss: 1.1556\n",
    "[Epoch 5] eval accuracy: 0.5778, loss: 1.1296"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain_Label:\n",
    "[Epoch 5] train accuracy: 0.8475, loss: 0.3743\n",
    "[Epoch 5] eval accuracy: 0.8133, loss: 0.4364"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
