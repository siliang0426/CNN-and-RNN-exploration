{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V0AWlNdsz5uo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\shigo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "import copy\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from absl import app, flags\n",
        "from skimage import io\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "task_type = 'training'\n",
        "experiment_name = 'exp'\n",
        "label_type = 'domain'\n",
        "learning_rate = 1e-4\n",
        "weight_decay = 0\n",
        "batch_size  = 256\n",
        "epochs = 5\n",
        "LABEL_SIZE = {'domain': 4, 'category': 7}\n",
        "\n",
        "class PACSDataset(Dataset):\n",
        "\n",
        "  def __init__(self,\n",
        "               root_dir,\n",
        "               label_type='domain',\n",
        "               is_training=False,\n",
        "               transform=None):\n",
        "    self.root_dir = os.path.join(root_dir, 'train' if is_training else 'val')\n",
        "    self.label_type = label_type\n",
        "    self.is_training = is_training\n",
        "    if transform:\n",
        "      self.transform = transform\n",
        "    else:\n",
        "      self.transform = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[0.7659, 0.7463, 0.7173],\n",
        "                               std=[0.3089, 0.3181, 0.3470]),\n",
        "      ])\n",
        "\n",
        "    self.dataset, self.label_list = self.initialize_dataset()\n",
        "    self.label_to_id = {x: i for i, x in enumerate(self.label_list)}\n",
        "    self.id_to_label = {i: x for i, x in enumerate(self.label_list)}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image, label = self.dataset[idx]\n",
        "    label_id = self.label_to_id[label]\n",
        "    image = self.transform(image)\n",
        "    return image, label_id\n",
        "\n",
        "  def initialize_dataset(self):\n",
        "    assert os.path.isdir(self.root_dir), \\\n",
        "        '`root_dir` is not found at %s' % self.root_dir\n",
        "\n",
        "    dataset = []\n",
        "    domain_set = set()\n",
        "    category_set = set()\n",
        "    cnt = 0\n",
        "\n",
        "    for root, dirs, files in os.walk(self.root_dir, topdown=True):\n",
        "      if files:\n",
        "        parts = root.split(os.sep)\n",
        "        if len(parts) >= 3:\n",
        "          domain = parts[-2]\n",
        "          category = parts[-1]\n",
        "          domain_set.add(domain)\n",
        "          category_set.add(category)\n",
        "          pbar = tqdm(files)\n",
        "          for name in pbar:\n",
        "            pbar.set_description('Processing Folder: domain=%s, category=%s' %\n",
        "                                (domain, category))\n",
        "            img_array = io.imread(os.path.join(root, name))\n",
        "            dataset.append((img_array, domain, category))\n",
        "    # use this below if you are running on google colab\n",
        "    # for root, dirs, files in os.walk(self.root_dir, topdown=True):\n",
        "    #   if files:\n",
        "    #     _, domain, category = root.rsplit('/', maxsplit=2)\n",
        "    #     domain_set.add(domain)\n",
        "    #     category_set.add(category)\n",
        "    #     pbar = tqdm(files)\n",
        "    #     for name in pbar:\n",
        "    #       pbar.set_description('Processing Folder: domain=%s, category=%s' %\n",
        "    #                            (domain, category))\n",
        "    #       img_array = io.imread(os.path.join(root, name))\n",
        "    #       dataset.append((img_array, domain, category))\n",
        "    images, domains, categories = zip(*dataset)\n",
        "\n",
        "    if self.label_type == 'domain':\n",
        "      labels = sorted(domain_set)\n",
        "      dataset = list(zip(images, domains))\n",
        "    elif self.label_type == 'category':\n",
        "      labels = sorted(category_set)\n",
        "      dataset = list(zip(images, categories))\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          'Unknown `label_type`: Expecting `domain` or `category`.')\n",
        "\n",
        "    return dataset, labels\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, configs):\n",
        "        super(AlexNet, self).__init__()\n",
        "        dropout = configs['dropout']\n",
        "        num_classes = configs['num_classes']\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "def model_training():\n",
        "\n",
        "  best_model = None\n",
        "  best_acc = 0.0\n",
        "\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  expt_name = 'experiments/{}/{}_lr_{}.wd_{}'.format(experiment_name, label_type, learning_rate, weight_decay)\n",
        "\n",
        "  os.makedirs(expt_name, exist_ok=True)\n",
        "  writer = SummaryWriter(log_dir=expt_name)\n",
        "\n",
        "  configs = {'num_classes': LABEL_SIZE[label_type], 'dropout': 0.5}\n",
        "\n",
        "  model = AlexNet(configs).to(device)\n",
        "\n",
        "  print('Model Architecture:\\n%s' % model)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "  optimizer = torch.optim.Adam(model.parameters(),\n",
        "                               lr=learning_rate,\n",
        "                               weight_decay=weight_decay)\n",
        "\n",
        "  try:\n",
        "    for epoch in range(epochs):\n",
        "      print(epoch)\n",
        "      for phase in ('train', 'eval'):\n",
        "        if phase == 'train':\n",
        "          model.train()\n",
        "          dataset = train_dataset\n",
        "          data_loader = train_loader\n",
        "        else:\n",
        "          model.eval()\n",
        "          dataset = val_dataset\n",
        "          data_loader = val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for step, (images, labels) in enumerate(data_loader):\n",
        "          print(step)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          with torch.set_grad_enabled(phase == 'train'):\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            if phase == 'train':\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              writer.add_scalar('Loss/{}'.format(phase), loss.item(),\n",
        "                                epoch * len(data_loader) + step)\n",
        "\n",
        "          running_loss += loss.item() * images.size(0)\n",
        "          running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataset)\n",
        "        writer.add_scalar('Epoch_Loss/{}'.format(phase), epoch_loss, epoch)\n",
        "        writer.add_scalar('Epoch_Accuracy/{}'.format(phase), epoch_acc, epoch)\n",
        "        print('[Epoch %d] %s accuracy: %.4f, loss: %.4f' %\n",
        "              (epoch + 1, phase, epoch_acc, epoch_loss))\n",
        "\n",
        "        if phase == 'eval':\n",
        "          if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model, os.path.join(expt_name, 'best_model.pt'))\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "  return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzvqYXkK7OwZ",
        "outputId": "3cbb2fa6-2a5f-41be-9410-738c45551992"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# Download the data\n",
        "\n",
        "!wget https://people.cs.pitt.edu/~mzhang/cs1699/pacs_dataset.zip\n",
        "!unzip pacs_dataset.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H16UKVTBTMc",
        "outputId": "854909f6-d48f-403e-b456-de752f187632"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing Folder: domain=art_painting, category=dog: 100%|██████████| 348/348 [00:00<00:00, 358.89it/s]\n",
            "Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 227/227 [00:00<00:00, 364.33it/s]\n",
            "Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 254/254 [00:00<00:00, 365.87it/s]\n",
            "Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 169/169 [00:00<00:00, 379.92it/s]\n",
            "Processing Folder: domain=art_painting, category=horse: 100%|██████████| 179/179 [00:00<00:00, 384.82it/s]\n",
            "Processing Folder: domain=art_painting, category=house: 100%|██████████| 262/262 [00:00<00:00, 366.07it/s]\n",
            "Processing Folder: domain=art_painting, category=person: 100%|██████████| 404/404 [00:01<00:00, 344.71it/s]\n",
            "Processing Folder: domain=cartoon, category=dog: 100%|██████████| 343/343 [00:00<00:00, 402.09it/s]\n",
            "Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 411/411 [00:01<00:00, 391.47it/s]\n",
            "Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 314/314 [00:00<00:00, 400.37it/s]\n",
            "Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 123/123 [00:00<00:00, 431.31it/s]\n",
            "Processing Folder: domain=cartoon, category=horse: 100%|██████████| 299/299 [00:00<00:00, 396.41it/s]\n",
            "Processing Folder: domain=cartoon, category=house: 100%|██████████| 266/266 [00:00<00:00, 407.86it/s]\n",
            "Processing Folder: domain=cartoon, category=person: 100%|██████████| 364/364 [00:00<00:00, 403.68it/s]\n",
            "Processing Folder: domain=photo, category=dog: 100%|██████████| 169/169 [00:00<00:00, 370.43it/s]\n",
            "Processing Folder: domain=photo, category=elephant: 100%|██████████| 181/181 [00:00<00:00, 378.32it/s]\n",
            "Processing Folder: domain=photo, category=giraffe: 100%|██████████| 165/165 [00:00<00:00, 355.02it/s]\n",
            "Processing Folder: domain=photo, category=guitar: 100%|██████████| 167/167 [00:00<00:00, 416.99it/s]\n",
            "Processing Folder: domain=photo, category=horse: 100%|██████████| 186/186 [00:00<00:00, 369.24it/s]\n",
            "Processing Folder: domain=photo, category=house: 100%|██████████| 243/243 [00:00<00:00, 378.64it/s]\n",
            "Processing Folder: domain=photo, category=person: 100%|██████████| 383/383 [00:01<00:00, 377.33it/s]\n",
            "Processing Folder: domain=sketch, category=dog: 100%|██████████| 697/697 [00:01<00:00, 380.59it/s]\n",
            "Processing Folder: domain=sketch, category=elephant: 100%|██████████| 674/674 [00:01<00:00, 390.03it/s]\n",
            "Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 681/681 [00:01<00:00, 387.35it/s]\n",
            "Processing Folder: domain=sketch, category=guitar: 100%|██████████| 564/564 [00:01<00:00, 392.23it/s]\n",
            "Processing Folder: domain=sketch, category=horse: 100%|██████████| 736/736 [00:01<00:00, 371.85it/s]\n",
            "Processing Folder: domain=sketch, category=house: 100%|██████████| 75/75 [00:00<00:00, 393.11it/s]\n",
            "Processing Folder: domain=sketch, category=person: 100%|██████████| 143/143 [00:00<00:00, 337.41it/s]\n",
            "Processing Folder: domain=art_painting, category=dog: 100%|██████████| 31/31 [00:00<00:00, 368.14it/s]\n",
            "Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 28/28 [00:00<00:00, 305.45it/s]\n",
            "Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 31/31 [00:00<00:00, 399.30it/s]\n",
            "Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 15/15 [00:00<00:00, 399.05it/s]\n",
            "Processing Folder: domain=art_painting, category=horse: 100%|██████████| 22/22 [00:00<00:00, 399.18it/s]\n",
            "Processing Folder: domain=art_painting, category=house: 100%|██████████| 33/33 [00:00<00:00, 346.72it/s]\n",
            "Processing Folder: domain=art_painting, category=person: 100%|██████████| 45/45 [00:00<00:00, 427.63it/s]\n",
            "Processing Folder: domain=cartoon, category=dog: 100%|██████████| 46/46 [00:00<00:00, 365.56it/s]\n",
            "Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 46/46 [00:00<00:00, 403.11it/s]\n",
            "Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 32/32 [00:00<00:00, 436.43it/s]\n",
            "Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 12/12 [00:00<00:00, 372.07it/s]\n",
            "Processing Folder: domain=cartoon, category=horse: 100%|██████████| 25/25 [00:00<00:00, 419.45it/s]\n",
            "Processing Folder: domain=cartoon, category=house: 100%|██████████| 22/22 [00:00<00:00, 434.49it/s]\n",
            "Processing Folder: domain=cartoon, category=person: 100%|██████████| 41/41 [00:00<00:00, 376.49it/s]\n",
            "Processing Folder: domain=photo, category=dog: 100%|██████████| 20/20 [00:00<00:00, 371.91it/s]\n",
            "Processing Folder: domain=photo, category=elephant: 100%|██████████| 21/21 [00:00<00:00, 452.07it/s]\n",
            "Processing Folder: domain=photo, category=giraffe: 100%|██████████| 17/17 [00:00<00:00, 416.49it/s]\n",
            "Processing Folder: domain=photo, category=guitar: 100%|██████████| 19/19 [00:00<00:00, 413.34it/s]\n",
            "Processing Folder: domain=photo, category=horse: 100%|██████████| 13/13 [00:00<00:00, 268.30it/s]\n",
            "Processing Folder: domain=photo, category=house: 100%|██████████| 37/37 [00:00<00:00, 434.55it/s]\n",
            "Processing Folder: domain=photo, category=person: 100%|██████████| 49/49 [00:00<00:00, 354.86it/s]\n",
            "Processing Folder: domain=sketch, category=dog: 100%|██████████| 75/75 [00:00<00:00, 417.71it/s]\n",
            "Processing Folder: domain=sketch, category=elephant: 100%|██████████| 66/66 [00:00<00:00, 338.35it/s]\n",
            "Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 72/72 [00:00<00:00, 349.05it/s]\n",
            "Processing Folder: domain=sketch, category=guitar: 100%|██████████| 44/44 [00:00<00:00, 371.58it/s]\n",
            "Processing Folder: domain=sketch, category=horse: 100%|██████████| 80/80 [00:00<00:00, 372.29it/s]\n",
            "Processing Folder: domain=sketch, category=house: 100%|██████████| 5/5 [00:00<00:00, 301.87it/s]\n",
            "Processing Folder: domain=sketch, category=person: 100%|██████████| 17/17 [00:00<00:00, 389.52it/s]\n"
          ]
        }
      ],
      "source": [
        "  # Make sure to run this before training the model\n",
        "\n",
        "  train_dataset = PACSDataset(root_dir='pacs_dataset',\n",
        "                              label_type=label_type,\n",
        "                              is_training=True)\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            num_workers=0)\n",
        "\n",
        "  val_dataset = PACSDataset(root_dir='pacs_dataset',\n",
        "                            label_type=label_type,\n",
        "                            is_training=False)\n",
        "  val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=False,\n",
        "                          num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf6d8sZp4NeQ",
        "outputId": "8889f5b0-aadf-4771-fd54-99ca20c6589a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Architecture:\n",
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Dropout(p=0.5, inplace=False)\n",
            "    (2): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Dropout(p=0.5, inplace=False)\n",
            "    (5): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Linear(in_features=4096, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "[Epoch 1] train accuracy: 0.6569, loss: 0.7078\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "[Epoch 1] eval accuracy: 0.7884, loss: 0.4490\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "[Epoch 2] train accuracy: 0.7595, loss: 0.4869\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "[Epoch 2] eval accuracy: 0.7842, loss: 0.4169\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "[Epoch 3] train accuracy: 0.8144, loss: 0.3969\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "[Epoch 3] eval accuracy: 0.8029, loss: 0.3910\n",
            "3\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "[Epoch 4] train accuracy: 0.8388, loss: 0.3665\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "[Epoch 4] eval accuracy: 0.8247, loss: 0.3580\n",
            "4\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "[Epoch 5] train accuracy: 0.8517, loss: 0.3467\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "[Epoch 5] eval accuracy: 0.8527, loss: 0.3052\n"
          ]
        }
      ],
      "source": [
        "# Train the model and output accuracy\n",
        "\n",
        "model_training()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Epoch 5] train accuracy: 0.8517, loss: 0.3467\n",
        "[Epoch 5] eval accuracy: 0.8527, loss: 0.3052\n",
        "\n",
        "With a smaller learning rate adjustment to the 1e-04, and a larger batch size of 256, the evaluation accuracy on the validation dataset comes to  0.84."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
