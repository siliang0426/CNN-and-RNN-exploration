{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qj3WkGyWsvfj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\shigo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "import copy\n",
        "import csv\n",
        "import os\n",
        "from io import StringIO\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from torch.distributions import categorical\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "# from google.colab import files\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCZwXydseGyN"
      },
      "source": [
        "# Before you start\n",
        "You need to save a copy in your own Google Drive then you could edit on this colab.\n",
        "\n",
        "Google offers free GPU in the colab environments, but you may need to configure the environment.\n",
        "\n",
        "You can turn on the GPU mode in `Edit -> Notebook Settings` and change the `Runtime type` to be `Python3` and `Hardware accelerator` to be `GPU`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUyrvJPYM4tQ",
        "outputId": "db32a617-a318-461c-f074-0c3730a12d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU Model: NVIDIA GeForce RTX 4080 Laptop GPU\n",
            "You should get either a Tesla P100 or Tesla T4 GPU.\n",
            "Tesla P100 is probably 3x faster than T4 but both should work.\n"
          ]
        }
      ],
      "source": [
        "print(\"GPU Model: %s\" % torch.cuda.get_device_name(0))\n",
        "print(\"You should get either a Tesla P100 or Tesla T4 GPU.\")\n",
        "print(\"Tesla P100 is probably 3x faster than T4 but both should work.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "writer = SummaryWriter('./')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EV09-LqPFxzD"
      },
      "outputs": [],
      "source": [
        "PADDING_TOKEN = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpvbH0YSRE99"
      },
      "source": [
        "# RNN modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P22Z9p3LKSBb"
      },
      "outputs": [],
      "source": [
        "class GRUCell(nn.Module):\n",
        "  \"\"\"Implementation of GRU cell from https://arxiv.org/pdf/1406.1078.pdf.\"\"\"\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, bias=False):\n",
        "    super().__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.bias = bias\n",
        "\n",
        "    # Learnable weights and bias for `update gate`\n",
        "    self.W_z = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "      self.b_z = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "      self.register_parameter('b_z', None)\n",
        "\n",
        "    # Learnable weights and bias for `reset gate`\n",
        "    self.W_r = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "      self.b_r = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "      self.register_parameter('b_r', None)\n",
        "\n",
        "    # Learnable weights and bias for `output gate`\n",
        "    self.W = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "      self.b = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "      self.register_parameter('b', None)\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def forward(self, x, prev_state):\n",
        "    if prev_state is None:\n",
        "      batch = x.shape[0]\n",
        "      prev_h = torch.zeros((batch, self.hidden_size), device=x.device)\n",
        "    else:\n",
        "      prev_h = prev_state\n",
        "\n",
        "    concat_hx = torch.cat((prev_h, x), dim=1)\n",
        "    z = torch.sigmoid(F.linear(concat_hx, self.W_z, self.b_z))\n",
        "    r = torch.sigmoid(F.linear(concat_hx, self.W_r, self.b_r))\n",
        "    h_tilde = torch.tanh(\n",
        "        F.linear(torch.cat((r * prev_h, x), dim=1), self.W, self.b))\n",
        "    next_h = (1 - z) * prev_h + z * h_tilde\n",
        "    return next_h\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    sqrt_k = (1. / self.hidden_size)**0.5\n",
        "    with torch.no_grad():\n",
        "      for param in self.parameters():\n",
        "        param.uniform_(-sqrt_k, sqrt_k)\n",
        "    return\n",
        "\n",
        "  def extra_repr(self):\n",
        "    return 'input_size={}, hidden_size={}, bias={}'.format(\n",
        "        self.input_size, self.hidden_size, self.bias is not True)\n",
        "\n",
        "  def count_parameters(self):\n",
        "    print('Total Parameters: %d' %\n",
        "          sum(p.numel() for p in self.parameters() if p.requires_grad))\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HTbx2lMiKYIs"
      },
      "outputs": [],
      "source": [
        "class LSTMCell(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, bias=True):\n",
        "    super().__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.bias = bias\n",
        "\n",
        "    # Learnable weights and bias for `input gate`\n",
        "    self.W_i = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "      self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "      self.register_parameter('b_i', None)\n",
        "\n",
        "    # Learnable weights and bias for `forget gate`\n",
        "    self.W_f = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "      self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "      self.register_parameter('b_f', None)\n",
        "\n",
        "    \n",
        "    # Learnable weights and bias for `output gate`\n",
        "    self.W_o = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "      self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "      self.register_parameter('b_o', None)\n",
        "\n",
        "    # Learnable weights and bias for `cell gate`\n",
        "    self.W_c = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "      self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "      self.register_parameter('b_c', None)\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def forward(self, x, prev_state):\n",
        "      if prev_state is None:\n",
        "          batch = x.shape[0]\n",
        "          prev_h = torch.zeros((batch, self.hidden_size), device=x.device)\n",
        "          prev_c = torch.zeros((batch, self.hidden_size), device=x.device)\n",
        "      else:\n",
        "          prev_h, prev_c = prev_state\n",
        "      \n",
        "      # Concatenate the previous hidden state and the current input\n",
        "      concat_hx = torch.cat((prev_h, x), dim=1)\n",
        "      \n",
        "      # Compute the input gate activation\n",
        "      i = torch.sigmoid(F.linear(concat_hx, self.W_i, self.b_i))\n",
        "      \n",
        "      # Compute the forget gate activation\n",
        "      f = torch.sigmoid(F.linear(concat_hx, self.W_f, self.b_f))\n",
        "      \n",
        "      # Compute the output gate activation\n",
        "      o = torch.sigmoid(F.linear(concat_hx, self.W_o, self.b_o))\n",
        "      \n",
        "      # Compute the cell gate (candidate) activation\n",
        "      c_tilde = torch.tanh(F.linear(concat_hx, self.W_c, self.b_c))\n",
        "      \n",
        "      # Update the cell state\n",
        "      c = f * prev_c + i * c_tilde\n",
        "      \n",
        "      # Compute the new hidden state\n",
        "      h = o * torch.tanh(c)\n",
        "      \n",
        "      return h, c\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    sqrt_k = (1. / self.hidden_size)**0.5\n",
        "    with torch.no_grad():\n",
        "      for param in self.parameters():\n",
        "        param.uniform_(-sqrt_k, sqrt_k)\n",
        "    return\n",
        "\n",
        "  def extra_repr(self):\n",
        "    return 'input_size={}, hidden_size={}, bias={}'.format(\n",
        "        self.input_size, self.hidden_size, self.bias is not True)\n",
        "\n",
        "  def count_parameters(self):\n",
        "    print('Total Parameters: %d' %\n",
        "          sum(p.numel() for p in self.parameters() if p.requires_grad))\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6ud8tBquKd61"
      },
      "outputs": [],
      "source": [
        "class PeepholedLSTMCell(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, bias=True):\n",
        "      super().__init__()\n",
        "      self.input_size = input_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.bias = bias\n",
        "\n",
        "      # Adjusting the sizes for the concatenated input: [C_{t-1}, h_{t-1}, x_t] and [C_t, h_{t-1}, x_t]\n",
        "      self.W_i = nn.Parameter(torch.Tensor(hidden_size, hidden_size*2 + input_size))\n",
        "      self.W_f = nn.Parameter(torch.Tensor(hidden_size, hidden_size*2 + input_size))\n",
        "      self.W_o = nn.Parameter(torch.Tensor(hidden_size, hidden_size*2 + input_size))\n",
        "      self.W_c = nn.Parameter(torch.Tensor(hidden_size, hidden_size*2 + input_size))\n",
        "\n",
        "      if bias:\n",
        "          self.b_i = nn.Parameter(torch.Tensor(hidden_size))\n",
        "          self.b_f = nn.Parameter(torch.Tensor(hidden_size))\n",
        "          self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
        "          self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
        "      else:\n",
        "          self.register_parameter('b_i', None)\n",
        "          self.register_parameter('b_f', None)\n",
        "          self.register_parameter('b_o', None)\n",
        "          self.register_parameter('b_c', None)\n",
        "\n",
        "      self.reset_parameters()\n",
        "\n",
        "  def forward(self, x, prev_state):\n",
        "      if prev_state is None:\n",
        "          batch_size = x.size(0)\n",
        "          prev_h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
        "          prev_c = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
        "      else:\n",
        "          prev_h, prev_c = prev_state\n",
        "\n",
        "      # Manually concatenate [C_{t-1}, h_{t-1}, x_t] for the inputs\n",
        "      concat_chx = torch.cat((prev_c, prev_h, x), dim=1)\n",
        "\n",
        "      # Apply the gates\n",
        "      i = torch.sigmoid(F.linear(concat_chx, self.W_i, self.b_i))\n",
        "      f = torch.sigmoid(F.linear(concat_chx, self.W_f, self.b_f))\n",
        "      g = torch.tanh(F.linear(concat_chx, self.W_c, self.b_c))\n",
        "\n",
        "      # Update cell state\n",
        "      c = f * prev_c + i * g\n",
        "\n",
        "      # For the output gate, now using [C_t, h_{t-1}, x_t]\n",
        "      concat_chx1 = torch.cat((c, prev_h, x), dim=1)\n",
        "      o = torch.sigmoid(F.linear(concat_chx1, self.W_o, self.b_o))\n",
        "\n",
        "      # Compute the new hidden state\n",
        "      h = o * torch.tanh(c)\n",
        "\n",
        "      return h, c\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    sqrt_k = (1. / self.hidden_size)**0.5\n",
        "    with torch.no_grad():\n",
        "      for param in self.parameters():\n",
        "        param.uniform_(-sqrt_k, sqrt_k)\n",
        "    return\n",
        "\n",
        "  def extra_repr(self):\n",
        "    return 'input_size={}, hidden_size={}, bias={}'.format(\n",
        "        self.input_size, self.hidden_size, self.bias is not True)\n",
        "\n",
        "  def count_parameters(self):\n",
        "    print('Total Parameters: %d' %\n",
        "          sum(p.numel() for p in self.parameters() if p.requires_grad))\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "J4nKRsHAKkwW"
      },
      "outputs": [],
      "source": [
        "class CoupledLSTMCell(nn.Module):\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, bias=True):\n",
        "    super(CoupledLSTMCell, self).__init__()\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.bias = bias\n",
        "\n",
        "    # Coupled input and forget gate weights\n",
        "    self.W_if = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "        self.b_if = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "        self.register_parameter('b_if', None)\n",
        "\n",
        "    # Output gate weights\n",
        "    self.W_o = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "        self.b_o = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "        self.register_parameter('b_o', None)\n",
        "\n",
        "    # Cell gate (candidate) weights\n",
        "    self.W_c = nn.Parameter(torch.Tensor(hidden_size, hidden_size + input_size))\n",
        "    if bias:\n",
        "        self.b_c = nn.Parameter(torch.Tensor(hidden_size))\n",
        "    else:\n",
        "        self.register_parameter('b_c', None)\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def forward(self, x, prev_state):\n",
        "    if prev_state is None:\n",
        "        batch_size = x.size(0)\n",
        "        prev_h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
        "        prev_c = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
        "    else:\n",
        "        prev_h, prev_c = prev_state\n",
        "\n",
        "    # Concatenate the previous hidden state and the current input\n",
        "    concat_hx = torch.cat((prev_h, x), dim=1)\n",
        "\n",
        "    # Coupled input and forget gate\n",
        "    if_gate = torch.sigmoid(F.linear(concat_hx, self.W_if, self.b_if))\n",
        "    i = if_gate  # Update (input) gate\n",
        "    f = 1 - if_gate  # Forget gate is simply 1 - input gate\n",
        "\n",
        "    # Cell gate (candidate)\n",
        "    g = torch.tanh(F.linear(concat_hx, self.W_c, self.b_c))\n",
        "\n",
        "    # Update the cell state\n",
        "    c = f * prev_c + i * g\n",
        "\n",
        "    # Output gate\n",
        "    o = torch.sigmoid(F.linear(concat_hx, self.W_o, self.b_o))\n",
        "\n",
        "    # Compute the new hidden state\n",
        "    h = o * torch.tanh(c)\n",
        "\n",
        "    return h, c\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    sqrt_k = (1. / self.hidden_size)**0.5\n",
        "    with torch.no_grad():\n",
        "      for param in self.parameters():\n",
        "        param.uniform_(-sqrt_k, sqrt_k)\n",
        "    return\n",
        "\n",
        "  def extra_repr(self):\n",
        "    return 'input_size={}, hidden_size={}, bias={}'.format(\n",
        "        self.input_size, self.hidden_size, self.bias is not True)\n",
        "\n",
        "  def count_parameters(self):\n",
        "    print('Total Parameters: %d' %\n",
        "          sum(p.numel() for p in self.parameters() if p.requires_grad))\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "plW2UsQlSGIl"
      },
      "outputs": [],
      "source": [
        "RNN_MODULES = {\n",
        "  'gru': GRUCell,\n",
        "  'lstm': LSTMCell,\n",
        "  'peepholed_lstm': PeepholedLSTMCell,\n",
        "  'coupled_lstm': CoupledLSTMCell,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1-I1OaIXPAx"
      },
      "source": [
        "# Upload data\n",
        "Please use the following code snippet to upload\n",
        "\n",
        "* imdb_train.csv\n",
        "* imdb_test.csv\n",
        "* shakespeare.txt\n",
        "\n",
        "You can choose multiple files to upload all at once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You Can choose the uncomment the below code if you are using google colab, I run it at the local environment since google colab would only allows you to train on CPU once the quota runs out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "2WvA8lDXPlOQ",
        "outputId": "3e0feeb4-182e-490b-9dc6-887410087169"
      },
      "outputs": [],
      "source": [
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OSI42Iv7U9iL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User uploaded file \"imdb_train.csv\" with length 60197565 bytes\n",
            "User uploaded file \"imdb_test.csv\" with length 6640779 bytes\n",
            "User uploaded file \"shakespeare.txt\" with length 1115394 bytes\n"
          ]
        }
      ],
      "source": [
        "def upload_files(file_paths):\n",
        "    \"\"\"\n",
        "    Mimics the behavior of files.upload() from Google Colab in a local environment.\n",
        "    Reads the specified files and returns a dictionary with file names as keys\n",
        "    and file contents as values.\n",
        "    \n",
        "    :param file_paths: A list of strings, where each string is a file path.\n",
        "    :return: A dictionary with file names as keys and file contents (as bytes) as values.\n",
        "    \"\"\"\n",
        "    uploaded = {}\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:  # Open the file in binary mode\n",
        "                uploaded[file_path.split('/')[-1]] = file.read()\n",
        "            print('User uploaded file \"{}\" with length {} bytes'.format(\n",
        "                file_path.split('/')[-1], len(uploaded[file_path.split('/')[-1]])\n",
        "            ))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_path}: {e}\")\n",
        "    return uploaded\n",
        "\n",
        "# Specify the paths to your files\n",
        "file_paths = [\n",
        "    'imdb_train.csv',\n",
        "    'imdb_test.csv',\n",
        "    'shakespeare.txt',\n",
        "]\n",
        "\n",
        "# Use the function to read the files\n",
        "uploaded = upload_files(file_paths)\n",
        "\n",
        "train_dataset_text = uploaded['imdb_train.csv']\n",
        "test_dataset_text = uploaded['imdb_test.csv']\n",
        "shakespeare_text = uploaded['shakespeare.txt']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ8MqD2HQ5SP"
      },
      "source": [
        "# Sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3eWmqa4OSkVY"
      },
      "outputs": [],
      "source": [
        "### Hyperparameters for training (previously defined in FLAGS)\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 0\n",
        "BATCH_SIZE = 4096\n",
        "EPOCHS = 51\n",
        "GRADIENT_CLIP_NORM = 1.0\n",
        "\n",
        "### Hyperparameters for sentence analysis model\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_SIZE = 100\n",
        "REVIEW_MAX_LENGTH = 200\n",
        "VOCABULARY_MIN_COUNT = 100\n",
        "VOCABULARY_MAX_SIZE = 20000\n",
        "RNN_MODULE = 'gru'    # You need to try 'lstm', 'peepholed_lstm', 'coupled_lstm'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mMoTuAy3ROgs"
      },
      "outputs": [],
      "source": [
        "class IMDBReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self,\n",
        "               csv_text,\n",
        "               vocabulary=None,\n",
        "               vocab_min_count=10,\n",
        "               vocab_max_size=None,\n",
        "               review_max_length=200):\n",
        "    self.csv_text = csv_text\n",
        "    self.vocab_min_count = vocab_min_count\n",
        "    self.vocab_max_size = vocab_max_size\n",
        "    self.review_max_length = review_max_length - 2\n",
        "\n",
        "    self.data = []\n",
        "\n",
        "    encoded_text = csv_text.strip().decode(encoding='utf-8')\n",
        "    fp = StringIO(encoded_text)\n",
        "    reader = csv.DictReader(fp, delimiter=',')\n",
        "    for row in tqdm(reader):\n",
        "      self.data.append((row['review'].split(' ')[:review_max_length],\n",
        "                        int(row['sentiment'] == 'positive')))\n",
        "    fp.close()\n",
        "\n",
        "    if vocabulary is not None:\n",
        "      print('Using external vocabulary - vocab-related configs ignored.')\n",
        "      self.vocabulary = vocabulary\n",
        "    else:\n",
        "      self.vocabulary = self._build_vocabulary()\n",
        "\n",
        "    self.word2index = {w: i for (i, w) in enumerate(self.vocabulary)}\n",
        "    self.index2word = {i: w for (i, w) in enumerate(self.vocabulary)}\n",
        "    self.oov_token_id = self.word2index['OOV_TOKEN']\n",
        "    self.pad_token_id = self.word2index['PAD_TOKEN']\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    review, label = self.data[index]\n",
        "    review = ['BEGIN_TOKEN'] + review + ['END_TOKEN']\n",
        "    token_ids = [self.word2index.get(w, self.oov_token_id) for w in review]\n",
        "    return token_ids, label\n",
        "\n",
        "  def _build_vocabulary(self):\n",
        "    special_tokens = ['PAD_TOKEN', 'BEGIN_TOKEN', 'OOV_TOKEN', 'END_TOKEN']\n",
        "\n",
        "    counter = collections.Counter()\n",
        "    for review, _ in self.data:\n",
        "      counter.update(review)\n",
        "\n",
        "    vocab = counter.most_common(self.vocab_max_size - 4)\n",
        "    if self.vocab_min_count is not None:\n",
        "      vocab_tokens = [w for (w, c) in vocab if c >= self.vocab_min_count]\n",
        "    else:\n",
        "      vocab_tokens, _ = zip(vocab)\n",
        "\n",
        "    return special_tokens + vocab_tokens\n",
        "\n",
        "  def get_vocabulary(self):\n",
        "    return self.vocabulary\n",
        "\n",
        "  def print_statistics(self):\n",
        "    reviews, labels = zip(*self.data)\n",
        "    lengths = [len(x) for x in reviews]\n",
        "    positive = np.sum(labels)\n",
        "    negative = len(labels) - positive\n",
        "    print('Total instances: %d, positive: %d, negative: %d' %\n",
        "          (len(self.data), positive, negative))\n",
        "    print('Review lengths: max: %d, min: %d, mean: %d, median: %d' %\n",
        "          (max(lengths), min(lengths), np.mean(lengths), np.median(lengths)))\n",
        "    print('Vocabulary size: %d' % len(self.vocabulary))\n",
        "    return\n",
        "\n",
        "\n",
        "def imdb_collate_fn(batch_data, padding_token_id=PADDING_TOKEN):\n",
        "  \"\"\"Padding variable-length sequences.\"\"\"\n",
        "  batch_tokens, batch_labels = zip(*batch_data)\n",
        "  lengths = [len(x) for x in batch_tokens]\n",
        "  max_length = max(lengths)\n",
        "\n",
        "  padded_tokens = []\n",
        "  for tokens, length in zip(batch_tokens, lengths):\n",
        "    padded_tokens.append(tokens + [padding_token_id] * (max_length - length))\n",
        "\n",
        "  padded_tokens = torch.tensor(padded_tokens, dtype=torch.int64)\n",
        "  lengths = torch.tensor(lengths, dtype=torch.int64)\n",
        "  labels = torch.tensor(batch_labels, dtype=torch.int64)\n",
        "\n",
        "  return padded_tokens, lengths, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PpEQBZJYPLbE"
      },
      "outputs": [],
      "source": [
        "class SentimentClassification(nn.Module):\n",
        "\n",
        "  def __init__(self,\n",
        "               vocabulary_size,\n",
        "               embedding_dim,\n",
        "               rnn_module,\n",
        "               hidden_size,\n",
        "               bias=False):\n",
        "    super().__init__()\n",
        "    self.vocabulary_size = vocabulary_size\n",
        "    self.rnn_module = rnn_module\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_size = hidden_size\n",
        "    self.bias = bias\n",
        "\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocabulary_size,\n",
        "                                  embedding_dim=embedding_dim,\n",
        "                                  padding_idx=PADDING_TOKEN)\n",
        "    self.rnn_model = self.rnn_module(input_size=embedding_dim,\n",
        "                                     hidden_size=hidden_size,\n",
        "                                     bias=bias)\n",
        "    self.classifier = nn.Linear(hidden_size, 2)\n",
        "    return\n",
        "\n",
        "  def forward(self, batch_reviews, batch_lengths):\n",
        "    data = self.embedding(batch_reviews)\n",
        "\n",
        "    state = None\n",
        "    batch_size, total_steps, _ = data.shape\n",
        "    full_outputs = []\n",
        "    for step in range(total_steps):\n",
        "      next_state = self.rnn_model(data[:, step, :], state)\n",
        "      if isinstance(next_state, tuple):\n",
        "        h, c = next_state\n",
        "        full_outputs.append(h)\n",
        "      else:\n",
        "        full_outputs.append(next_state)\n",
        "      state = next_state\n",
        "\n",
        "    full_outputs = torch.stack(full_outputs, dim=1)\n",
        "    outputs = full_outputs[torch.arange(batch_size), batch_lengths - 1, :]\n",
        "    logits = self.classifier(outputs)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IqrED-lZPeSr"
      },
      "outputs": [],
      "source": [
        "def imdb_trainer(batch_size, epochs):\n",
        "  writer = SummaryWriter()\n",
        "  train_dataset = IMDBReviewDataset(csv_text=train_dataset_text,\n",
        "                                    vocab_min_count=VOCABULARY_MIN_COUNT,\n",
        "                                    vocab_max_size=VOCABULARY_MAX_SIZE,\n",
        "                                    review_max_length=REVIEW_MAX_LENGTH)\n",
        "  train_dataset.print_statistics()\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            num_workers=0,\n",
        "                            collate_fn=imdb_collate_fn)\n",
        "  vocabulary = train_dataset.get_vocabulary()\n",
        "\n",
        "  # Validation dataset should use the same vocabulary as the training set.\n",
        "  val_dataset = IMDBReviewDataset(csv_text=test_dataset_text,\n",
        "                                  vocabulary=vocabulary,\n",
        "                                  review_max_length=REVIEW_MAX_LENGTH)\n",
        "  val_dataset.print_statistics()\n",
        "  val_loader = DataLoader(val_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=False,\n",
        "                          num_workers=0,\n",
        "                          collate_fn=imdb_collate_fn)\n",
        "\n",
        "  best_model = None\n",
        "  best_acc = 0.0\n",
        "\n",
        "  full_train_loss = []\n",
        "  full_train_accuracy = []\n",
        "  full_val_loss = []\n",
        "  full_val_accuracy = []\n",
        "\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  model = SentimentClassification(vocabulary_size=len(vocabulary),\n",
        "                                  embedding_dim=EMBEDDING_DIM,\n",
        "                                  rnn_module=RNN_MODULES[RNN_MODULE],\n",
        "                                  hidden_size=HIDDEN_SIZE)\n",
        "  \n",
        "  model.to(device)\n",
        "\n",
        "  model.rnn_model.count_parameters()\n",
        "\n",
        "  print('Model Architecture:\\n%s' % model)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "  optimizer = torch.optim.Adam(model.parameters(),\n",
        "                               lr=LEARNING_RATE,\n",
        "                               weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    for phase in ('train', 'eval'):\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "        dataset = train_dataset\n",
        "        data_loader = train_loader\n",
        "      else:\n",
        "        model.eval()\n",
        "        dataset = val_dataset\n",
        "        data_loader = val_loader\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      for step, (reviews, lengths, labels) in tqdm(enumerate(data_loader)):\n",
        "        reviews = reviews.to(device)\n",
        "        lengths = lengths.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = model(reviews, lengths)\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "\n",
        "            # RNN model is easily getting exploded gradients, thus we perform\n",
        "            # gradients clipping to mitigate this issue.\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), GRADIENT_CLIP_NORM)\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * reviews.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "      epoch_loss = running_loss / len(dataset)\n",
        "      epoch_acc = running_corrects.double() / len(dataset)\n",
        "      if phase == 'train':\n",
        "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
        "        full_train_accuracy.append(epoch_acc)\n",
        "        full_train_loss.append(epoch_loss)\n",
        "      elif phase == 'eval':\n",
        "        writer.add_scalar('Loss/val', epoch_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/val', epoch_acc, epoch)\n",
        "        full_val_accuracy.append(epoch_acc)\n",
        "        full_val_loss.append(epoch_loss)\n",
        "\n",
        "      print('[Epoch %d] %s accuracy: %.4f, loss: %.4f' %\n",
        "            (epoch + 1, phase, epoch_acc, epoch_loss))\n",
        "\n",
        "      if phase == 'eval':\n",
        "        if epoch_acc > best_acc:\n",
        "          best_acc = epoch_acc\n",
        "          best_model = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  # state_dict = {\"model\": best_model.cpu().state_dict(),\n",
        "  #               \"vocabulary\": vocabulary}\n",
        "  print(\"Best validation accuracy: %.4f\" % best_acc)\n",
        "  logs = (full_train_loss, full_train_accuracy, full_val_loss, full_val_accuracy)\n",
        "\n",
        "  writer.close()\n",
        "  return logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "3Wzb82juVUkM",
        "outputId": "d47514a3-9a24-4838-b53b-1bfe75b04e00"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "390bd22ac54d436eaaec24fdb1a70b27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total instances: 45000, positive: 22500, negative: 22500\n",
            "Review lengths: max: 200, min: 8, mean: 168, median: 198\n",
            "Vocabulary size: 4835\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3af4750c7a6746368cb5083078a95b56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using external vocabulary - vocab-related configs ignored.\n",
            "Total instances: 5000, positive: 2500, negative: 2500\n",
            "Review lengths: max: 200, min: 11, mean: 167, median: 195\n",
            "Vocabulary size: 4835\n",
            "Total Parameters: 68400\n",
            "Model Architecture:\n",
            "SentimentClassification(\n",
            "  (embedding): Embedding(4835, 128, padding_idx=0)\n",
            "  (rnn_model): GRUCell(input_size=128, hidden_size=100, bias=True)\n",
            "  (classifier): Linear(in_features=100, out_features=2, bias=True)\n",
            ")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "455d0c4113104d0683affb3c71ff4b66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1] train accuracy: 0.5027, loss: 0.7004\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70e02121bfc14239839b16542fabbac7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1] eval accuracy: 0.5222, loss: 0.6919\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d2011c310e242a8bab0ae861cc451ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 2] train accuracy: 0.5414, loss: 0.6871\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7af0849f7d374ca3828d6d42e4f468f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 2] eval accuracy: 0.5456, loss: 0.6859\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df69763af6c04b278285dd8cd25f1452",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 3] train accuracy: 0.5668, loss: 0.6793\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4273d15bc82f43dca5015d711b544b35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 3] eval accuracy: 0.5722, loss: 0.6760\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93efbb9e682141a3bb100f7682b4b7fe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 4] train accuracy: 0.5972, loss: 0.6607\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f5f4c2b580c4fbcb56ec109845b6fc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 4] eval accuracy: 0.6230, loss: 0.6454\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "111bc7ec3a884a44a18ee83ca17659e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 5] train accuracy: 0.6735, loss: 0.6123\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "845c5a17fdf446b5852fb38669fcb137",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 5] eval accuracy: 0.6768, loss: 0.6011\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2528c8405fd84ea4b350e21763cd41c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 6] train accuracy: 0.7159, loss: 0.5608\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf1ebb6ae93449278313c33ee6d91d21",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 6] eval accuracy: 0.7288, loss: 0.5453\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41575478857345899690d31002a0f947",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 7] train accuracy: 0.7646, loss: 0.5006\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "900748c01c3945aa9a9047ab9aeadbd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 7] eval accuracy: 0.7656, loss: 0.4961\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e381f2c7e747508be2f63525efbca6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 8] train accuracy: 0.7917, loss: 0.4576\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4d63fbcea67415e94561307715be2ee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 8] eval accuracy: 0.7716, loss: 0.4918\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4243c8d2743460282398bcf84fc7289",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 9] train accuracy: 0.7997, loss: 0.4443\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e7b37d7c11c474b9cc1a890b1383ee7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 9] eval accuracy: 0.7946, loss: 0.4560\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbec0b99e4ab461b92ade3d691e841ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 10] train accuracy: 0.8242, loss: 0.4024\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82379233a83a4970be4728dfbd74e62a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 10] eval accuracy: 0.8108, loss: 0.4327\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24541eed24924ee3bd5246835ac563b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 11] train accuracy: 0.8364, loss: 0.3809\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1f22093decd4352b30a0f7e526fc5f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 11] eval accuracy: 0.8152, loss: 0.4231\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33b70b85b80c47e1b7dbcd9e1ef77ea3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 12] train accuracy: 0.8494, loss: 0.3608\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a91d1e3999a4c42be909989ce395d39",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 12] eval accuracy: 0.8228, loss: 0.4170\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5b1ee323ec249038e992a365eb138df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 13] train accuracy: 0.8578, loss: 0.3444\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6cd25e7e4554cec8cee9e2e725b621b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 13] eval accuracy: 0.8306, loss: 0.4044\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f05eb3f68214c00bd40e800eaefae98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 14] train accuracy: 0.8640, loss: 0.3312\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14dfb24b42044ea08be8325fa1b0af6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 14] eval accuracy: 0.8370, loss: 0.4019\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "769217a4e1304b6b976fd098ca6f098d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 15] train accuracy: 0.8691, loss: 0.3214\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f53ffd02d09436e9f1237ee5001621d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 15] eval accuracy: 0.8392, loss: 0.3849\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1442d1c02644007b9bd8cabbc0e55c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 16] train accuracy: 0.8732, loss: 0.3119\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bb0ce09a82947208b6045594c02e02d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 16] eval accuracy: 0.8362, loss: 0.3874\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "354d9911fd4f494891e30109fd7e8a9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 17] train accuracy: 0.8792, loss: 0.3022\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f8f2166ec4846fd8626a185d55af894",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 17] eval accuracy: 0.8424, loss: 0.3881\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e661b0b3e6b64c5bab68c3d2b5eb8060",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 18] train accuracy: 0.8851, loss: 0.2896\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a421656fc17e4968b3aa12c5d8fc9b0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 18] eval accuracy: 0.8388, loss: 0.3957\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "574a30a1bfc444bb9cf138d3b956d20d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 19] train accuracy: 0.8882, loss: 0.2820\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7254ebe04614f6d90be30e454dcfddd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 19] eval accuracy: 0.8444, loss: 0.3834\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b10da15dd6e46cfb96c5f8f86f7d7c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 20] train accuracy: 0.8921, loss: 0.2749\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb9e890ec47c45f2ab50aa21984c728e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 20] eval accuracy: 0.8446, loss: 0.3902\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40d9203f545e4931a4bee83c24344d0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 21] train accuracy: 0.8954, loss: 0.2680\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a48080822ae347bf8644c3a9acaa896d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 21] eval accuracy: 0.8430, loss: 0.3802\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9045a52b81184dd08a5b173923207633",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 22] train accuracy: 0.8986, loss: 0.2616\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97d7075ffff643e5b7503cc3cb809b31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 22] eval accuracy: 0.8444, loss: 0.3853\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "654dd4b911a24c2384abcd4dab7cf91a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 23] train accuracy: 0.9012, loss: 0.2555\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "66d6b706acbf42a4bc1b2fe388115ecd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 23] eval accuracy: 0.8506, loss: 0.3811\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fc2f321ddd94e9698c51cac439e0727",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 24] train accuracy: 0.9055, loss: 0.2478\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78acbe95511044f784e51ac383698a68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 24] eval accuracy: 0.8528, loss: 0.3724\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e517b98f86f442b9aae2c08fad4fd544",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 25] train accuracy: 0.9073, loss: 0.2436\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f7112fd5f6a43a99bc39ecc09cb177c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 25] eval accuracy: 0.8490, loss: 0.3788\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "859a5ea8ad3f4233ab2ebbb1dc5c5a2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 26] train accuracy: 0.9105, loss: 0.2374\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2a27584b66d4c01a43942ae75806fa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 26] eval accuracy: 0.8502, loss: 0.3770\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0ac326a779142ed92b33f2b4e6bf00c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 27] train accuracy: 0.9123, loss: 0.2333\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6769a16da9f2483ebe0d4f4306295ef3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 27] eval accuracy: 0.8540, loss: 0.3777\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6e046f88ebd4065a122c7d7d9aad14b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 28] train accuracy: 0.9146, loss: 0.2282\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55fec36670f14b4ab0fa58e5a6af4544",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 28] eval accuracy: 0.8548, loss: 0.3773\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "187920209b4f471983e3a1db1709da8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 29] train accuracy: 0.9189, loss: 0.2223\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "844066f413e14794a139ce7f90c14db9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 29] eval accuracy: 0.8506, loss: 0.3781\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "928da3b5fc3d43b5ba7d615d7b43456f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 30] train accuracy: 0.9208, loss: 0.2161\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce2e6b08db3c47c6b4a3492ff6ed719a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 30] eval accuracy: 0.8528, loss: 0.3850\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d880b144ec714bd797e9ece364c8d063",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 31] train accuracy: 0.9218, loss: 0.2120\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a6582fb56a804573898b85d7273943d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 31] eval accuracy: 0.8568, loss: 0.3777\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a36147d41e945fbab06c99740ce996c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 32] train accuracy: 0.9239, loss: 0.2069\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de1c7bb698a64922858b02a717d5997b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 32] eval accuracy: 0.8534, loss: 0.3912\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "667dbc176b2f413b880bf2abffc9e140",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 33] train accuracy: 0.9261, loss: 0.2033\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64b9f5a663ba4a60aa1a7b6039998225",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 33] eval accuracy: 0.8546, loss: 0.3745\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e48b8dccbfae47ffb36e9f92a21b7dda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 34] train accuracy: 0.9279, loss: 0.1996\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79fd712299c140ddae5d10840730e7d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 34] eval accuracy: 0.8518, loss: 0.3894\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b81d529359804bc683f52af12d7b291b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 35] train accuracy: 0.9301, loss: 0.1948\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a93753b807c64a56a97c811faa952a3e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 35] eval accuracy: 0.8552, loss: 0.3803\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db9495909db64cc190d7640f0dd47c64",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 36] train accuracy: 0.9325, loss: 0.1900\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "263ae2ad0cc84ef180274fb4dfa8a687",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 36] eval accuracy: 0.8574, loss: 0.3826\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22c1d6ba409c4814a17267438331f7d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 37] train accuracy: 0.9322, loss: 0.1881\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fd62c4484ed4f27b7b637018e907e41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 37] eval accuracy: 0.8500, loss: 0.3996\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c82696aebad4ec88920e1b28807ba37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 38] train accuracy: 0.9364, loss: 0.1811\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea91622f04de4196b238a210c847a1b0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 38] eval accuracy: 0.8522, loss: 0.3955\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e007e0a4bc6247c18d1993afa7c77d59",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 39] train accuracy: 0.9371, loss: 0.1794\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62b37d2db531480e913b907c3ecd7eea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 39] eval accuracy: 0.8598, loss: 0.3824\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e57755b3aae4289bf524ab1dace6a44",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 40] train accuracy: 0.9383, loss: 0.1751\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13e74674aa17405890a16d3bd05ad90b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 40] eval accuracy: 0.8540, loss: 0.4073\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "907779b20a0445bcbebc32db33677b47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 41] train accuracy: 0.9381, loss: 0.1763\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "220b219392694c9899cf1b70bcb6caf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 41] eval accuracy: 0.8518, loss: 0.4198\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "380d0dc747d4432fa7e929423ff88c24",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 42] train accuracy: 0.9408, loss: 0.1691\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efa41a22d6ea424ab6ad6a62384d0481",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 42] eval accuracy: 0.8524, loss: 0.3916\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff172a40ca034f7f8cac4fa52bbad5fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 43] train accuracy: 0.9426, loss: 0.1645\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3281d751634d402eb3176e64684f1d0a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 43] eval accuracy: 0.8602, loss: 0.4099\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12f4001809e14e6f80f91a678136210c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 44] train accuracy: 0.9458, loss: 0.1593\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f53e0a854034ec2be2b46dd55e2060c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 44] eval accuracy: 0.8602, loss: 0.4260\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d0977782ddc46e894b20930315826fd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 45] train accuracy: 0.9478, loss: 0.1559\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c841df4948f41bcbb8d6bf9e366174d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 45] eval accuracy: 0.8506, loss: 0.4152\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6effad2c2c9c43aeaac78cee55f1a197",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 46] train accuracy: 0.9479, loss: 0.1539\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17f83bbc482345fd948fa833249498ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 46] eval accuracy: 0.8530, loss: 0.3918\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21fd74ccccb4493bbf8b9d1c51033abc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 47] train accuracy: 0.9494, loss: 0.1508\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cda271044cd24dc5b903097c06cbe945",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 47] eval accuracy: 0.8616, loss: 0.4351\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72a7d5c1761b4f57a36b653bdfee8fcc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 48] train accuracy: 0.9517, loss: 0.1456\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ad3923725e64cb094e7427a1992e204",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 48] eval accuracy: 0.8600, loss: 0.4376\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "77f6b0ffca0e4c40b9df65181381e7f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 49] train accuracy: 0.9534, loss: 0.1411\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "030b8f4f949e49038f2886787f3cd704",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 49] eval accuracy: 0.8518, loss: 0.4141\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c18469a74af4193ac683f58246fcb94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 50] train accuracy: 0.9555, loss: 0.1370\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f1ec1f38a964101ae4d1faf6e6e8eb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 50] eval accuracy: 0.8498, loss: 0.4330\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fd544c8ca914219b7e65e3326ff9236",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 51] train accuracy: 0.9564, loss: 0.1345\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "714bb2caf4294255b755ed70f35391b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 51] eval accuracy: 0.8594, loss: 0.4140\n",
            "Best validation accuracy: 0.8616\n"
          ]
        }
      ],
      "source": [
        "logs = imdb_trainer(BATCH_SIZE, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "aX0Jewz2iZ8r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 20232), started 15:52:10 ago. (Use '!kill 20232' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-46cee4b7b585c1c3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-46cee4b7b585c1c3\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### You can make a plot using matplotlib with logs\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoIIj56qRZkG"
      },
      "source": [
        "# Language model and sentence generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "i-A1T4jSYD90"
      },
      "outputs": [],
      "source": [
        "### Hyperparameters for training (previously defined in FLAGS)\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 0\n",
        "BATCH_SIZE = 4096\n",
        "EPOCHS = 10\n",
        "\n",
        "### Hyperparameters for sentence analysis model\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_SIZE = 512\n",
        "RNN_MODULE = 'gru'\n",
        "HISTORY_LENGTH = 100\n",
        "\n",
        "### Hyperparameters for generating new sentence\n",
        "GENERATION_LENGTH = 2000\n",
        "START_STRING = 'JULIET'\n",
        "TEMPERATURE = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "eU55O-zoC8Xp"
      },
      "outputs": [],
      "source": [
        "class ShakespeareDataset(Dataset):\n",
        "\n",
        "  def __init__(self, encoded_text, history_length):\n",
        "    self.encoded_text = encoded_text\n",
        "    self.history_length = history_length\n",
        "\n",
        "    raw_text = self.encoded_text.strip().decode(encoding='utf-8')\n",
        "\n",
        "    self.vocab = sorted(set(raw_text))\n",
        "    self.char2index = {x: i for (i, x) in enumerate(self.vocab)}\n",
        "    self.index2char = {i: x for (i, x) in enumerate(self.vocab)}\n",
        "\n",
        "    self.data = [(raw_text[i:i + history_length], raw_text[i + history_length])\n",
        "                 for i in range(len(raw_text) - history_length)]\n",
        "    return\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    history, label = self.data[index]\n",
        "    history = np.array([self.char2index[x] for x in history])\n",
        "    label = self.char2index[label]\n",
        "    return history, label\n",
        "\n",
        "  def get_vocabulary(self):\n",
        "    return self.vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6i53RH0ADB5L"
      },
      "outputs": [],
      "source": [
        "class SentenceGeneration(nn.Module):\n",
        "\n",
        "  def __init__(self,\n",
        "               vocabulary_size,\n",
        "               embedding_dim,\n",
        "               rnn_module,\n",
        "               hidden_size,\n",
        "               bias=False):\n",
        "    super().__init__()\n",
        "    self.vocabulary_size = vocabulary_size\n",
        "    self.rnn_module = rnn_module\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_size = hidden_size\n",
        "    self.bias = bias\n",
        "\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocabulary_size,\n",
        "                                  embedding_dim=embedding_dim,\n",
        "                                  padding_idx=PADDING_TOKEN)\n",
        "    self.rnn_model = self.rnn_module(input_size=embedding_dim,\n",
        "                                     hidden_size=hidden_size,\n",
        "                                     bias=bias)\n",
        "    self.classifier = nn.Linear(hidden_size, vocabulary_size)\n",
        "    return\n",
        "\n",
        "  def forward(self, batch_reviews, state=None):\n",
        "    data = self.embedding(batch_reviews)\n",
        "\n",
        "    batch_size, total_steps, _ = data.shape\n",
        "    for step in range(total_steps):\n",
        "      next_state = self.rnn_model(data[:, step, :], state)\n",
        "      if isinstance(next_state, tuple):\n",
        "        h, c = next_state\n",
        "        outputs = h\n",
        "      else:\n",
        "        outputs = next_state\n",
        "      state = next_state\n",
        "\n",
        "    logits = self.classifier(outputs)\n",
        "    return logits, state\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    with torch.no_grad:\n",
        "      for param in self.parameters():\n",
        "        param.reset_parameters()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kHF55Pa-D4xc"
      },
      "outputs": [],
      "source": [
        "def shakespeare_trainer(batch_size, epochs):\n",
        "  train_dataset = ShakespeareDataset(encoded_text=shakespeare_text,\n",
        "                                     history_length=HISTORY_LENGTH)\n",
        "\n",
        "  print('Train dataset: %d' % len(train_dataset))\n",
        "\n",
        "  train_loader = DataLoader(train_dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            num_workers=0)\n",
        "  vocabulary = train_dataset.get_vocabulary()\n",
        "\n",
        "  best_model = None\n",
        "  best_loss = 0.0\n",
        "  full_loss = []\n",
        "\n",
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  model = SentenceGeneration(vocabulary_size=len(vocabulary),\n",
        "                             embedding_dim=EMBEDDING_DIM,\n",
        "                             rnn_module=RNN_MODULES[RNN_MODULE],\n",
        "                             hidden_size=HIDDEN_SIZE)\n",
        "  model.to(device)\n",
        "\n",
        "  print('Model Architecture:\\n%s' % model)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss(reduction='mean')\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    dataset = train_dataset\n",
        "    data_loader = train_loader\n",
        "\n",
        "    progress_bar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
        "    for step, (sequences, labels) in progress_bar:\n",
        "      total_step = epoch * len(data_loader) + step\n",
        "      sequences = sequences.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs, _ = model(sequences)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      loss = criterion(outputs, labels)\n",
        "      corrects = torch.sum(preds == labels.data)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      progress_bar.set_description(\n",
        "          'Loss: %.4f, Accuracy: %.4f' %\n",
        "          (loss.item(), corrects.item() / len(labels)))\n",
        "      full_loss.append(loss.item())\n",
        "\n",
        "  state_dict = {\"model\": model.cpu().state_dict(),\n",
        "                \"vocabulary\": vocabulary}\n",
        "\n",
        "  return state_dict, full_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "IhtpdJufFN6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset: 1115293\n",
            "Model Architecture:\n",
            "SentenceGeneration(\n",
            "  (embedding): Embedding(65, 256, padding_idx=0)\n",
            "  (rnn_model): GRUCell(input_size=256, hidden_size=512, bias=True)\n",
            "  (classifier): Linear(in_features=512, out_features=65, bias=True)\n",
            ")\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56e365613fdb4235a1381d75ca9e4508",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2dc66a3ab1d0421784cd50140bb84058",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "224eb3405be44af399c16d9d872a4990",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c8efe16ffeab48f196c3354fe33fe0c6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e6c1beede87427e99f48b79790538ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2086259111fc41db935da3de0cf3e85e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e1c261cbbbc4086bce8056df5daf82d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d88f980a1bad453aaf48ef46b39442d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7f5099abe5e473890047511fcd1029b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18c39fd34a30407888913459e4b08301",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/273 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "final_model, loss = shakespeare_trainer(batch_size=BATCH_SIZE,\n",
        "                                        epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGHfkuR0QCRB"
      },
      "outputs": [],
      "source": [
        "### You can make a plot using matplotlib with loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DXHS1g2DsovI"
      },
      "outputs": [],
      "source": [
        "def sample_next_char_id(predicted_logits):\n",
        "  next_char_id = categorical.Categorical(logits=predicted_logits).sample()\n",
        "  return next_char_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2VqD2C1FNHAQ"
      },
      "outputs": [],
      "source": [
        "def shakespeare_writer(state_dict, start_string):\n",
        "  \"\"\"Generates new sentences using trained language model.\"\"\"\n",
        "  device = 'cpu'\n",
        "\n",
        "  vocabulary = state_dict['vocabulary']\n",
        "\n",
        "  char2index = {x: i for (i, x) in enumerate(vocabulary)}\n",
        "  index2char = {i: x for (i, x) in enumerate(vocabulary)}\n",
        "\n",
        "  inputs = torch.tensor([char2index[x] for x in start_string])\n",
        "  inputs = inputs.view(1, -1)\n",
        "\n",
        "  model = SentenceGeneration(vocabulary_size=len(vocabulary),\n",
        "                             embedding_dim=EMBEDDING_DIM,\n",
        "                             rnn_module=RNN_MODULES[RNN_MODULE],\n",
        "                             hidden_size=HIDDEN_SIZE)\n",
        "\n",
        "  model.load_state_dict(state_dict['model'])\n",
        "  model.eval()\n",
        "\n",
        "  generated_chars = []\n",
        "  hidden = None\n",
        "  #####################################################################\n",
        "  # Implement here for generating new sentence                        #\n",
        "  # Specifically, you need to iterate through the history and predict #\n",
        "  # next character; then you could take the predicted history as part #\n",
        "  # of history then repeat the process. The generation should be      #\n",
        "  # repeated for FLAGS.generation_length times.\n",
        "  #####################################################################\n",
        "  # Convert start string to tensor\n",
        "  inputs = inputs.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for _ in range(GENERATION_LENGTH):\n",
        "          output, hidden = model(inputs, hidden)\n",
        "          # Adjust indexing based on actual output dimensions\n",
        "          predicted_logits = output.squeeze()  # Removing sequence length dimension since it's likely 1\n",
        "          predicted_char_id = sample_next_char_id(predicted_logits).item()\n",
        "          generated_chars.append(index2char[predicted_char_id])\n",
        "          # Update inputs for the next iteration\n",
        "          inputs = torch.tensor([[predicted_char_id]], dtype=torch.long, device=device)\n",
        "\n",
        "  return start_string + ''.join(generated_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ap_S3JkANJoL"
      },
      "outputs": [],
      "source": [
        "generated_text_romeo = shakespeare_writer(final_model, START_STRING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "No, now, to fail them will away his pace.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Go thou: 'tis but body to go you apparel in\n",
            "The hole word. Your zoundly dust I have said,\n",
            "It wounds you in the morning's nor question gross;\n",
            "Our father remove your worship in as he\n",
            "thess, stand and fongues and terrions in this.\n",
            "\n",
            "GRUMIO:\n",
            "How do your father cast? Perchiard, I\n",
            "may not poor Henry for Rome.\n",
            "\n",
            "VIRGILIA:\n",
            "In that! I had rememperous the head of all\n",
            "walting hate, carries a dream--\n",
            "\n",
            "BRUTUS:\n",
            "Sirrah, tell you, let us share guilty hearing.\n",
            "He bears the battle and makes their waters\n",
            "To want thee shall I to be put am.\n",
            "\n",
            "RIVINE:\n",
            "Been in my great creysure of the earth\n",
            "Distipline. Your worship.\n",
            "\n",
            "ESCALUS:\n",
            "Which was the church is reddel is lord!\n",
            "\n",
            "GRUMIO:\n",
            "I tell you, my inchard-bed, fie! But, dear days:\n",
            "Clumb Siges no withood he stands most one\n",
            "Of a king as, breast of reople? Thou confess'd,\n",
            "If you, if this, have obeybed at it.\n",
            "Anon, brother, I pray you: here being it;\n",
            "Your graced freely do is for even lies:\n",
            "Speak with you; I will slow earth help from mistress!\n",
            "Thy boy\n",
            "Will fetch him no more for her lives before.\n",
            "\n",
            "RATCLIFF:\n",
            "Good my lord, to the dishonour of\n",
            "'forced him, or boy, I am so angry\n",
            "Would sit not; and that'll thank his penitenced\n",
            "Enough the city's foot in some stranglance\n",
            "As I vially ke firfuly; we have wanders\n",
            "To glad you can beg act.\n",
            "\n",
            "LARCIUS:\n",
            "What are you?\n",
            "\n",
            "First Citizen:\n",
            "'Clarence.\n",
            "\n",
            "VIRGILIA:\n",
            "I think he is a toubtile child: must fet!\n",
            "\n",
            "Second Mowranta!'\n",
            "For nothing is banish'd with hers, baise,\n",
            "I ware, by whose happy adders the exder,\n",
            "While I do't. I cannot much to do us;\n",
            "Not one honour'd of thee mourn, that he studies\n",
            "May stay them, where is her childish crowns.\n",
            "Herein be of night, Tranio.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Come, sir; we'll give them not what our wretch cannot\n",
            "Be they deliver'd and in any earled,\n",
            "Whose swift will sour her power, forbodimmand,\n",
            "Let's baukill. Your daughter terrs and fire\n",
            "Generations, banished strail! I know him.\n",
            "\n",
            "DUKE OF York:\n",
            "The foot mayor I out you that loves the wall:\n",
            "As to thy pres\n"
          ]
        }
      ],
      "source": [
        "print(generated_text_romeo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "generated_text_juliet = shakespeare_writer(final_model, START_STRING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JULIET:\n",
            "Call off is it bight our three again; I word,\n",
            "What answer Bolingbroke's to the Towem.\n",
            "Here's to yaunt?\n",
            "O Tybalt, wouldst law before thy book!\n",
            "O day, cannot speak, shout on thee till I\n",
            "And say this throw their voices\n",
            "Till her sacrus. I warraguide another,\n",
            "When apellion whom could end our beards, and breathe\n",
            "very straight: to my followers make a tormently\n",
            "and our bacely issue: I will tell him there\n",
            "of forside this fellow:\n",
            "And was not her; even some spirits upon\n",
            "When I have not suspect to enmite\n",
            "Our swords to this inglight to her back:\n",
            "What to the son, that you shall be move,\n",
            "Like a foul wrecks for me, or heard him pack'd\n",
            "Your cortalieve on me. I am my encrease\n",
            "Or no more; spoke her wants to counsel a house\n",
            "And leave it thus bestrid thy throat,\n",
            "And yet put thee to her justice: the queen's chaste,\n",
            "And let my shadow hands with warlike out.\n",
            "\n",
            "PETERILA:\n",
            "Is it fall louded, sir:\n",
            "But that say you shall requite my tent:\n",
            "Down and reasons, I will sets on her:\n",
            "Shall I be of our worscian, whose oath not thine?\n",
            "\n",
            "HORTENSIO:\n",
            "Madam?\n",
            "\n",
            "First Servant:\n",
            "Adieu, though you redress up thy schoolmaster\n",
            "Toour innocant: this eye did scarr us,\n",
            "By the case beloved my profetters! my Post,\n",
            "What meet but honour is reign'd and a jest\n",
            "Of right leet and forgiveness saying they'\n",
            "\n",
            "Stag with persuasizard loudersmet,\n",
            "Whatfell to you, and send a frial sent,\n",
            "Whom impeach's main before ze love to get:\n",
            "The moin of runs such a course of idle.\n",
            "\n",
            "RICHARD:\n",
            "Fortunion shall I be?\n",
            "\n",
            "KATHARINA:\n",
            "Unherivedly for thy speech and that\n",
            "Which such as greater beast off some maids\n",
            "And two days to find us better one,\n",
            "Father how make the least in JUFor Edward's boy.\n",
            "The mills and be spirits fear me all,\n",
            "That hangs on measure so saw her: he,--\n",
            "\n",
            "ESCALUS:\n",
            "I am in our anguish hearing, which now, your bones\n",
            "Consider from hence hath fiers. Or\n",
            "As practise she assay this as she is\n",
            "corror down to make our stays in them\n",
            "Against her perfancies as subplicated a\n",
            "daughters that. Take the sin of this noses;\n",
            "If thither would have made tell you de\n"
          ]
        }
      ],
      "source": [
        "print(generated_text_juliet)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
