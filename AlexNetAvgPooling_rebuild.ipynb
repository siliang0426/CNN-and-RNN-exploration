{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from absl import app, flags\n",
    "from skimage import io\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "task_type = 'training'\n",
    "experiment_name = 'exp'\n",
    "label_type = 'domain'\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0\n",
    "batch_size  = 256\n",
    "epochs = 5\n",
    "LABEL_SIZE = {'domain': 4, 'category': 7}\n",
    "\n",
    "class PACSDataset(Dataset):\n",
    "\n",
    "  def __init__(self,\n",
    "               root_dir,\n",
    "               label_type='domain',\n",
    "               is_training=False,\n",
    "               transform=None):\n",
    "    self.root_dir = os.path.join(root_dir, 'train' if is_training else 'val')\n",
    "    self.label_type = label_type\n",
    "    self.is_training = is_training\n",
    "    if transform:\n",
    "      self.transform = transform\n",
    "    else:\n",
    "      self.transform = transforms.Compose([\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize(mean=[0.7659, 0.7463, 0.7173],\n",
    "                               std=[0.3089, 0.3181, 0.3470]),\n",
    "      ])\n",
    "\n",
    "    self.dataset, self.label_list = self.initialize_dataset()\n",
    "    self.label_to_id = {x: i for i, x in enumerate(self.label_list)}\n",
    "    self.id_to_label = {i: x for i, x in enumerate(self.label_list)}\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image, label = self.dataset[idx]\n",
    "    label_id = self.label_to_id[label]\n",
    "    image = self.transform(image)\n",
    "    return image, label_id\n",
    "\n",
    "  def initialize_dataset(self):\n",
    "    assert os.path.isdir(self.root_dir), \\\n",
    "        '`root_dir` is not found at %s' % self.root_dir\n",
    "\n",
    "    dataset = []\n",
    "    domain_set = set()\n",
    "    category_set = set()\n",
    "    cnt = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(self.root_dir, topdown=True):\n",
    "      if files:\n",
    "        parts = root.split(os.sep)\n",
    "        if len(parts) >= 3:\n",
    "          domain = parts[-2]\n",
    "          category = parts[-1]\n",
    "          domain_set.add(domain)\n",
    "          category_set.add(category)\n",
    "          pbar = tqdm(files)\n",
    "          for name in pbar:\n",
    "            pbar.set_description('Processing Folder: domain=%s, category=%s' %\n",
    "                                (domain, category))\n",
    "            img_array = io.imread(os.path.join(root, name))\n",
    "            dataset.append((img_array, domain, category))\n",
    "\n",
    "    # use this below if you are running on google colab\n",
    "    # for root, dirs, files in os.walk(self.root_dir, topdown=True):\n",
    "    #   if files:\n",
    "    #     _, domain, category = root.rsplit('/', maxsplit=2)\n",
    "    #     domain_set.add(domain)\n",
    "    #     category_set.add(category)\n",
    "    #     pbar = tqdm(files)\n",
    "    #     for name in pbar:\n",
    "    #       pbar.set_description('Processing Folder: domain=%s, category=%s' %\n",
    "    #                            (domain, category))\n",
    "    #       img_array = io.imread(os.path.join(root, name))\n",
    "    #       dataset.append((img_array, domain, category))\n",
    "    images, domains, categories = zip(*dataset)\n",
    "\n",
    "    if self.label_type == 'domain':\n",
    "      labels = sorted(domain_set)\n",
    "      dataset = list(zip(images, domains))\n",
    "    elif self.label_type == 'category':\n",
    "      labels = sorted(category_set)\n",
    "      dataset = list(zip(images, categories))\n",
    "    else:\n",
    "      raise ValueError(\n",
    "          'Unknown `label_type`: Expecting `domain` or `category`.')\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "\n",
    "class AlexNetAvgPooling(nn.Module):\n",
    "\n",
    "  def __init__(self, configs):\n",
    "    super().__init__()\n",
    "    dropout = configs['dropout']\n",
    "    num_classes = configs['num_classes']\n",
    "\n",
    "    self.features = nn.Sequential(\n",
    "      nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.AvgPool2d(kernel_size=3, stride=2),\n",
    "      nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.AvgPool2d(kernel_size=3, stride=2),\n",
    "      nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.AvgPool2d(kernel_size=3, stride=2)\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Dropout(dropout),\n",
    "      nn.Linear(9216, 4096),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Dropout(dropout),\n",
    "      nn.Linear(4096, 4096),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(4096, num_classes)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "\n",
    "def model_training():\n",
    "\n",
    "  best_model = None\n",
    "  best_acc = 0.0\n",
    "\n",
    "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "  expt_name = 'experiments/{}/{}_lr_{}.wd_{}'.format(experiment_name, label_type, learning_rate, weight_decay)\n",
    "\n",
    "  os.makedirs(expt_name, exist_ok=True)\n",
    "  writer = SummaryWriter(log_dir=expt_name)\n",
    "\n",
    "  configs = {'num_classes': LABEL_SIZE[label_type], 'dropout': 0.5}\n",
    "\n",
    "  model = AlexNetAvgPooling(configs).to(device)\n",
    "\n",
    "  print('Model Architecture:\\n%s' % model)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "  optimizer = torch.optim.Adam(model.parameters(),\n",
    "                               lr=learning_rate,\n",
    "                               weight_decay=weight_decay)\n",
    "\n",
    "  try:\n",
    "    for epoch in range(epochs):\n",
    "      print(epoch)\n",
    "      for phase in ('train', 'eval'):\n",
    "        if phase == 'train':\n",
    "          model.train()\n",
    "          dataset = train_dataset\n",
    "          data_loader = train_loader\n",
    "        else:\n",
    "          model.eval()\n",
    "          dataset = val_dataset\n",
    "          data_loader = val_loader\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for step, (images, labels) in enumerate(data_loader):\n",
    "          print(step)\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          with torch.set_grad_enabled(phase == 'train'):\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if phase == 'train':\n",
    "              loss.backward()\n",
    "              optimizer.step()\n",
    "\n",
    "              writer.add_scalar('Loss/{}'.format(phase), loss.item(),\n",
    "                                epoch * len(data_loader) + step)\n",
    "\n",
    "          running_loss += loss.item() * images.size(0)\n",
    "          running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataset)\n",
    "        writer.add_scalar('Epoch_Loss/{}'.format(phase), epoch_loss, epoch)\n",
    "        writer.add_scalar('Epoch_Accuracy/{}'.format(phase), epoch_acc, epoch)\n",
    "        print('[Epoch %d] %s accuracy: %.4f, loss: %.4f' %\n",
    "              (epoch + 1, phase, epoch_acc, epoch_loss))\n",
    "\n",
    "        if phase == 'eval':\n",
    "          if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            torch.save(best_model, os.path.join(expt_name, 'best_model.pt'))\n",
    "\n",
    "  except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Folder: domain=art_painting, category=dog: 100%|██████████| 348/348 [00:01<00:00, 335.12it/s]\n",
      "Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 227/227 [00:00<00:00, 340.72it/s]\n",
      "Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 254/254 [00:00<00:00, 354.35it/s]\n",
      "Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 169/169 [00:00<00:00, 352.19it/s]\n",
      "Processing Folder: domain=art_painting, category=horse: 100%|██████████| 179/179 [00:00<00:00, 403.16it/s]\n",
      "Processing Folder: domain=art_painting, category=house: 100%|██████████| 262/262 [00:00<00:00, 359.47it/s]\n",
      "Processing Folder: domain=art_painting, category=person: 100%|██████████| 404/404 [00:01<00:00, 379.53it/s]\n",
      "Processing Folder: domain=cartoon, category=dog: 100%|██████████| 343/343 [00:01<00:00, 335.81it/s]\n",
      "Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 411/411 [00:01<00:00, 321.39it/s]\n",
      "Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 314/314 [00:01<00:00, 219.56it/s]\n",
      "Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 123/123 [00:01<00:00, 79.27it/s]\n",
      "Processing Folder: domain=cartoon, category=horse: 100%|██████████| 299/299 [00:00<00:00, 372.70it/s]\n",
      "Processing Folder: domain=cartoon, category=house: 100%|██████████| 266/266 [00:00<00:00, 312.97it/s]\n",
      "Processing Folder: domain=cartoon, category=person: 100%|██████████| 364/364 [00:01<00:00, 330.63it/s]\n",
      "Processing Folder: domain=photo, category=dog: 100%|██████████| 169/169 [00:07<00:00, 22.73it/s]\n",
      "Processing Folder: domain=photo, category=elephant: 100%|██████████| 181/181 [00:00<00:00, 355.15it/s]\n",
      "Processing Folder: domain=photo, category=giraffe: 100%|██████████| 165/165 [00:00<00:00, 341.37it/s]\n",
      "Processing Folder: domain=photo, category=guitar: 100%|██████████| 167/167 [00:00<00:00, 376.15it/s]\n",
      "Processing Folder: domain=photo, category=horse: 100%|██████████| 186/186 [00:00<00:00, 360.52it/s]\n",
      "Processing Folder: domain=photo, category=house: 100%|██████████| 243/243 [00:00<00:00, 342.53it/s]\n",
      "Processing Folder: domain=photo, category=person: 100%|██████████| 383/383 [00:01<00:00, 371.40it/s]\n",
      "Processing Folder: domain=sketch, category=dog: 100%|██████████| 697/697 [00:01<00:00, 363.94it/s]\n",
      "Processing Folder: domain=sketch, category=elephant: 100%|██████████| 674/674 [00:01<00:00, 340.71it/s]\n",
      "Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 681/681 [00:01<00:00, 352.50it/s]\n",
      "Processing Folder: domain=sketch, category=guitar: 100%|██████████| 564/564 [00:01<00:00, 360.06it/s]\n",
      "Processing Folder: domain=sketch, category=horse: 100%|██████████| 736/736 [00:01<00:00, 378.51it/s]\n",
      "Processing Folder: domain=sketch, category=house: 100%|██████████| 75/75 [00:00<00:00, 389.38it/s]\n",
      "Processing Folder: domain=sketch, category=person: 100%|██████████| 143/143 [00:00<00:00, 384.53it/s]\n",
      "Processing Folder: domain=art_painting, category=dog: 100%|██████████| 31/31 [00:00<00:00, 412.09it/s]\n",
      "Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 28/28 [00:00<00:00, 414.84it/s]\n",
      "Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 31/31 [00:00<00:00, 328.54it/s]\n",
      "Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 15/15 [00:00<00:00, 335.94it/s]\n",
      "Processing Folder: domain=art_painting, category=horse: 100%|██████████| 22/22 [00:00<00:00, 363.84it/s]\n",
      "Processing Folder: domain=art_painting, category=house: 100%|██████████| 33/33 [00:00<00:00, 317.40it/s]\n",
      "Processing Folder: domain=art_painting, category=person: 100%|██████████| 45/45 [00:00<00:00, 261.29it/s]\n",
      "Processing Folder: domain=cartoon, category=dog: 100%|██████████| 46/46 [00:00<00:00, 296.97it/s]\n",
      "Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 46/46 [00:00<00:00, 329.43it/s]\n",
      "Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 32/32 [00:00<00:00, 339.33it/s]\n",
      "Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 12/12 [00:00<00:00, 350.21it/s]\n",
      "Processing Folder: domain=cartoon, category=horse: 100%|██████████| 25/25 [00:00<00:00, 309.42it/s]\n",
      "Processing Folder: domain=cartoon, category=house: 100%|██████████| 22/22 [00:00<00:00, 316.83it/s]\n",
      "Processing Folder: domain=cartoon, category=person: 100%|██████████| 41/41 [00:00<00:00, 313.53it/s]\n",
      "Processing Folder: domain=photo, category=dog: 100%|██████████| 20/20 [00:00<00:00, 295.63it/s]\n",
      "Processing Folder: domain=photo, category=elephant: 100%|██████████| 21/21 [00:00<00:00, 386.24it/s]\n",
      "Processing Folder: domain=photo, category=giraffe: 100%|██████████| 17/17 [00:00<00:00, 404.96it/s]\n",
      "Processing Folder: domain=photo, category=guitar: 100%|██████████| 19/19 [00:00<00:00, 399.84it/s]\n",
      "Processing Folder: domain=photo, category=horse: 100%|██████████| 13/13 [00:00<00:00, 305.05it/s]\n",
      "Processing Folder: domain=photo, category=house: 100%|██████████| 37/37 [00:00<00:00, 350.31it/s]\n",
      "Processing Folder: domain=photo, category=person: 100%|██████████| 49/49 [00:00<00:00, 296.16it/s]\n",
      "Processing Folder: domain=sketch, category=dog: 100%|██████████| 75/75 [00:00<00:00, 312.27it/s]\n",
      "Processing Folder: domain=sketch, category=elephant: 100%|██████████| 66/66 [00:00<00:00, 350.45it/s]\n",
      "Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 72/72 [00:00<00:00, 321.34it/s]\n",
      "Processing Folder: domain=sketch, category=guitar: 100%|██████████| 44/44 [00:00<00:00, 296.23it/s]\n",
      "Processing Folder: domain=sketch, category=horse: 100%|██████████| 80/80 [00:00<00:00, 348.18it/s]\n",
      "Processing Folder: domain=sketch, category=house: 100%|██████████| 5/5 [00:00<00:00, 390.21it/s]\n",
      "Processing Folder: domain=sketch, category=person: 100%|██████████| 17/17 [00:00<00:00, 302.80it/s]\n"
     ]
    }
   ],
   "source": [
    "  train_dataset = PACSDataset(root_dir='pacs_dataset',\n",
    "                              label_type=label_type,\n",
    "                              is_training=True)\n",
    "  train_loader = DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0)\n",
    "\n",
    "  val_dataset = PACSDataset(root_dir='pacs_dataset',\n",
    "                            label_type=label_type,\n",
    "                            is_training=False)\n",
    "  val_loader = DataLoader(val_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=False,\n",
    "                          num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "AlexNetAvgPooling(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): AvgPool2d(kernel_size=3, stride=2, padding=0)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Linear(in_features=4096, out_features=4, bias=True)\n",
      "  )\n",
      ")\n",
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 1] train accuracy: 0.6611, loss: 0.7533\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 1] eval accuracy: 0.7469, loss: 0.5908\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 2] train accuracy: 0.7558, loss: 0.5522\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 2] eval accuracy: 0.7500, loss: 0.5792\n",
      "2\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 3] train accuracy: 0.7859, loss: 0.4863\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 3] eval accuracy: 0.7977, loss: 0.4359\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 4] train accuracy: 0.8197, loss: 0.4135\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 4] eval accuracy: 0.8268, loss: 0.3907\n",
      "4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "[Epoch 5] train accuracy: 0.8393, loss: 0.3773\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "[Epoch 5] eval accuracy: 0.8174, loss: 0.5252\n"
     ]
    }
   ],
   "source": [
    "model_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Category_Label:\n",
    "[Epoch 5] train accuracy: 0.5259, loss: 1.2511\n",
    "[Epoch 5] eval accuracy: 0.5467, loss: 1.2039"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain_Label:\n",
    "[Epoch 5] train accuracy: 0.8393, loss: 0.3773\n",
    "[Epoch 5] eval accuracy: 0.8174, loss: 0.5252"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
